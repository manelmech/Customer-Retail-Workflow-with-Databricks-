{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "016cae16-efbd-492b-bb4d-d0a46e0fc6d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Read the data from each state\n",
    "df_ca = spark.read.table(\"ecommerce.retail_customer.customers_orders_ca_silver\")\n",
    "df_ny = spark.read.table(\"ecommerce.retail_customer.customers_orders_ny_silver\")\n",
    "df_va = spark.read.table(\"ecommerce.retail_customer.customers_orders_va_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d19143bf-0520-4a44-ba33-2e6bd87c1c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "## -- COMMON CLEANING AND STANDARDIZATION --\n",
    "def clean_common(df):\n",
    "    df = df.toDF(*[c.strip() for c in df.columns])\n",
    "    df = df.withColumn(\"customer_name\", F.initcap(F.trim(F.col(\"customer_name\"))))\n",
    "    \n",
    "    ''' Correct Code\n",
    "    df = df.withColumn(\"customer_name\", F.initcap(F.trim(F.col(\"custmer\")))\n",
    "    '''\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e7df8e-f23e-4368-b643-c7283d901824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --CALIFONIA TRANSFORMATION --\n",
    "def prep_ca(df_ca):\n",
    "    df = clean_common(df_ca)\n",
    "    # Fill missing cities with 'Unknown'\n",
    "    df = df.withColumn(\"city\", F.when(F.col(\"city\").isNull(), F.lit(\"Unlnown\")).otherwise(F.col(\"city\")))\n",
    "    # Extract order month and large order flag\n",
    "    df = df.withColumn( \"order_month\", F.date_format(\"order_date\", \"yyyy-MM\"))\n",
    "    # Custom: Add column for Souther CA city marker \n",
    "    so_cal_cities = [\"Los Angeles\", \"San Diego\", \"BBakersfiel\", \"Anaheim\", \"Long Beach\"]\n",
    "    df = df.withColumn(\n",
    "        \"is_southern_ca\",\n",
    "        F.lower(F.col(\"city\")).isin([c.lower() for c in so_cal_cities])\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b083c5f-3b29-409d-a7bc-f290ed8bdbda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#--NEW YORK TRANSFORMATION--\n",
    "def prep_ny(df_ny):\n",
    "    df = clean_common(df_ny)\n",
    "    # Fill missing cities with \"Unspecified\"\n",
    "    df = df.withColumn(\"city\", F.when(F.col(\"city\").isNull(), F.lit(\"Unspecified\")).otherwise(F.col(\"city\")) )\n",
    "    # Assigning NY region group \n",
    "    my_upstate_cities = [\"Buffalo\", \"Rochester\", \"Albany\", \"Syracuse\"]\n",
    "    my_downstate_cities =[\"Yonkers\", \"White Plains\"]\n",
    "\n",
    "    df = df.withColumn(\"my_region\", (F.when(F.col(\"city\").isin([c for c in my_upstate_cities]), F.lit(\"Upstate\")) \n",
    "                                     .when(F.col(\"city\").isin([c for c in my_downstate_cities]), F.lit(\"Downstate\"))\n",
    "                                     .otherwise(F.lit(\"Other\")) ))\n",
    "    \n",
    "    df = df.withColumn(\"order_week\", F.weekofyear(\"order_date\"))\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b89316b-a410-4ff7-b82f-2961d7479959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-- VIRGINIA TRANSFORMATION -- \n",
    "def prep_va(df_va):\n",
    "    \n",
    "    df = clean_common(df_va)\n",
    "    # Fill missing city as 'Other'\n",
    "    df = df.withColumn(\"city\", F.when(F.col(\"city\").isNull(), F.lit(\"Other\")).otherwise(F.col(\"city\")))\n",
    "    # Segment orders by size \n",
    "    df = df.withColumn(\"order_size_label\", F.when(F.col(\"is_large_order\") == \"true\", F.lit(\"Large\")).otherwise(F.lit(\"Regular\")))\n",
    "    # Extract order day of week \n",
    "    df = df.withColumn(\"order_day_of_week\", F.date_format(\"order_date\", \"E\"))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fbad249-517f-487f-94d6-5f0798f9cc7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -- APPLY TRANSFORMATION --\n",
    "df_ca_clean = prep_ca(df_ca)\n",
    "df_ny_clean = prep_ny(df_ny)\n",
    "df_va_clean = prep_va(df_va)\n",
    "\n",
    "# -- Write To tables --\n",
    "df_ca_clean.write.mode(\"overwrite\").saveAsTable(\"ecommerce.retail_customer.customers_orders_ca_gold\")\n",
    "df_ny_clean.write.mode(\"overwrite\").saveAsTable(\"ecommerce.retail_customer.customers_orders_ny_gold\")\n",
    "df_va_clean.write.mode(\"overwrite\").saveAsTable(\"ecommerce.retail_customer.customers_orders_va_gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3fe74f-2a3e-43da-b689-5362717976b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES IN system.lakeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d385dff9-fb1c-4371-b42b-75e68444fc19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM system.lakeflow.jobs\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6616154721344678,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1.9 Tranforming Customer Orders State",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
